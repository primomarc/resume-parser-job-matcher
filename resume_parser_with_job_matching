import fitz  # PyMuPDF
import spacy
import requests
import json

# Load a more advanced spaCy NLP model
nlp = spacy.load("en_core_web_trf")

# Indeed API Key (Replace with your actual API key)
INDEED_API_KEY = "YOUR_INDEED_API_KEY"
INDEED_API_URL = "https://api.indeed.com/v2/job/search"

def extract_text_from_pdf(pdf_path):
    """Extract text from a PDF file."""
    doc = fitz.open(pdf_path)
    text = "\n".join([page.get_text("text") for page in doc])
    return text

def extract_job_titles_and_skills(text):
    """Extract job titles and skills from resume text using NLP."""
    doc = nlp(text)
    job_titles = []
    skills = []
    
    # Predefined list of common job titles
    common_job_titles = {"Software Engineer", "Data Analyst", "Web Developer", "Project Manager", "Data Scientist",
                         "Machine Learning Engineer", "Front-End Developer", "Back-End Developer", "Full-Stack Developer",
                         "Business Analyst", "DevOps Engineer", "Cybersecurity Analyst", "Network Engineer", "Database Administrator"}
    
    # Extract job titles using Named Entity Recognition (NER)
    for ent in doc.ents:
        if ent.label_ in ["PERSON", "ORG", "TITLE"] or ent.text in common_job_titles:
            if any(keyword in ent.text.lower() for keyword in ["engineer", "developer", "analyst", "manager", "scientist"]):
                job_titles.append(ent.text)
    
    # Extract skills, filtering common job-related keywords
    for ent in doc.ents:
        if ent.label_ in ["ORG", "PRODUCT"]:  # Skills may be misclassified
            skills.append(ent.text)
    
    # Filter out irrelevant skills using a predefined skill set
    valid_skills = {"Python", "JavaScript", "SQL", "Data Analysis", "HTML", "CSS", "Bootstrap", "Git", "Excel"}
    filtered_skills = [skill for skill in skills if skill in valid_skills]
    
    return list(set(job_titles)), filtered_skills

def fetch_jobs_from_indeed(skills, location="remote"):
    """Fetch job listings from Indeed API based on skills."""
    params = {
        "q": " ".join(skills),  # Search for jobs matching extracted skills
        "l": location,  # Search for remote jobs
        "apikey": INDEED_API_KEY,
        "format": "json",
        "limit": 10  # Number of jobs to fetch
    }
    
    response = requests.get(INDEED_API_URL, params=params)
    if response.status_code == 200:
        jobs = response.json().get("jobs", [])
        return jobs
    else:
        print("Error fetching jobs from Indeed API:", response.text)
        return []

if __name__ == "__main__":
    pdf_path = r"C:\Users\Admin\Desktop\Resume Parser\resume.pdf"  # Update with actual file path
    resume_text = extract_text_from_pdf(pdf_path)
    job_titles, skills = extract_job_titles_and_skills(resume_text)
    
    print("Extracted Job Titles:", job_titles)
    print("Extracted Skills:", skills)
    
    job_matches = fetch_jobs_from_indeed(skills)
    
    print("\nBest Matching Jobs:")
    for job in job_matches:
        print(f"{job['title']} at {job['company']} - {job['location']}")
        print(f"Apply Here: {job['url']}\n")
